/**
 * Copyright (c) 2013 National University of Ireland, Galway. All Rights Reserved.
 */
package org.sindice.graphsummary.iotransformation;

import java.util.Arrays;
import java.util.Set;
import java.util.TreeSet;

import org.apache.commons.lang.StringUtils;
import org.apache.hadoop.io.BytesWritable;
import org.sindice.core.analytics.testHelper.iotransformation.AbstractFieldType;
import org.sindice.core.analytics.util.Hash;
import org.sindice.graphsummary.cascading.ecluster.fbisimulation.FBisimulationProcess;

import cascading.flow.FlowProcess;

/**
 * Creates a cluster identifier that is generated by the {@link FBisimulationProcess} algorithm.
 * <p>
 * Each line represents the identifier of clusters, with the first one being the identifier of the
 * current entity, and the subsequent ones the identifiers of outgoing connected clusters.
 * <p>
 * The identifier of a cluster consists in the {@link Hash#getHash128(byte[]) hash} of an entity's signature,
 * i.e., the set of attributes and types attached to it.
 * <p>
 * The components of a cluster identifier are separated with the character <code>'|'</code>.
 * In the case where an entity connects two ore more different clusters, their identifier are separated
 * with the character <code>'*'</code>.
 * For example, consider a cluster with identifier <code>p1|t1</code>, connected to two clusters with
 * identifiers <code>p2|t2</code> and <code>p3|t3</code>.
 * This configuration is written as follows:
 * <pre>
 * p1|t1
 * p2|t2*p3|t3
 * </pre>
 */
public class FBisimulationCidType
extends AbstractFieldType<BytesWritable> {

  public FBisimulationCidType(FlowProcess fp, String s) {
    super(fp, s);
  }

  @Override
  public BytesWritable doConvert() {
    final StringBuilder sb = new StringBuilder();
    final String[] splits = StringUtils.split(this.input, "\n");
    final BytesWritable[] cids = new BytesWritable[splits.length];

    final Set<BytesWritable> set = new TreeSet<BytesWritable>();

    // Compute the hash of each split
    for (int i = 0; i < splits.length; i++) {
      set.clear();
      final String[] s = StringUtils.split(splits[i], "*");
      for (final String part : s) {
        final String[] p = StringUtils.split(part, "|");
        Arrays.sort(p);
        sb.setLength(0);
        for (String value : p) {
          sb.append(value);
        }
        set.add(Hash.getHash128(sb));
      }
      final byte[] bytes = new byte[set.size() * 16];
      int pos = 0;
      for (BytesWritable bw: set) {
        System.arraycopy(bw.getBytes(), 0, bytes, pos, 16);
        pos += 16;
      }
      cids[i] = new BytesWritable(bytes);
    }

    // Compute the final CID
    BytesWritable prev = null;
    for (int i = cids.length - 1; i >= 0; i--) {
      if (i == cids.length - 1) {
        prev = cids[i];
      } else {
        prev = Hash.getHash128(concatCID(cids[i], prev));
      }
    }
    return prev;
  }

  /**
   * Return the concatenation of both CIDs.
   * @param cid the ID of the current cluster
   * @param childrenCid the IDs of the children clusters
   * @return a byte[] which is the concatenation of both CIDs arrays
   */
  private byte[] concatCID(final BytesWritable cid,
                           final BytesWritable childrenCid) {
    final byte[] bytes = new byte[cid.getLength() + childrenCid.getLength()];

    System.arraycopy(cid.getBytes(), 0, bytes, 0, cid.getLength());
    System.arraycopy(childrenCid.getBytes(), 0, bytes, cid.getLength(), childrenCid.getLength());
    return bytes;
  }

  @Override
  protected BytesWritable getEmptyField() {
    return new BytesWritable();
  }

}

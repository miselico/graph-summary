/**
 * Copyright (c) 2012 National University of Ireland, Galway. All Rights Reserved.
 */
package org.sindice.core.analytics.cascading.scheme;

import java.io.BufferedInputStream;
import java.io.BufferedOutputStream;
import java.io.IOException;
import java.util.Arrays;
import java.util.zip.ZipEntry;
import java.util.zip.ZipOutputStream;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.FileUtil;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.MapFile;
import org.apache.hadoop.io.SequenceFile.CompressionType;
import org.apache.hadoop.io.Writable;
import org.apache.hadoop.io.WritableComparable;
import org.apache.hadoop.io.compress.CompressionCodec;
import org.apache.hadoop.io.compress.DefaultCodec;
import org.apache.hadoop.mapred.FileOutputFormat;
import org.apache.hadoop.mapred.JobConf;
import org.apache.hadoop.mapred.Partitioner;
import org.apache.hadoop.mapred.RecordWriter;
import org.apache.hadoop.mapred.Reporter;
import org.apache.hadoop.mapred.SequenceFileOutputFormat;
import org.apache.hadoop.util.Progressable;
import org.apache.hadoop.util.ReflectionUtils;

/**
 * This {@link FileOutputFormat} creates a Zip archive of a {@link MapFile}.
 */
public class ZipMapFileOutputFormat
extends FileOutputFormat<WritableComparable, Writable> {

  public static final String MAPFILE_ZIP_NAME = "mapfile.zip";

  private final String[]     mfFiles          = { "data", "index" };

  @Override
  public RecordWriter<WritableComparable, Writable> getRecordWriter(
      FileSystem ignored, JobConf job, String name, Progressable progress)
      throws IOException {
    // get the path of the temporary output file
    final Path file = FileOutputFormat.getTaskOutputPath(job, name);

    final FileSystem fs = file.getFileSystem(job);
    CompressionCodec codec = null;
    CompressionType compressionType = CompressionType.NONE;
    if (getCompressOutput(job)) {
      // find the kind of compression to do
      compressionType = SequenceFileOutputFormat.getOutputCompressionType(job);

      // find the right codec
      Class<? extends CompressionCodec> codecClass = getOutputCompressorClass(
          job, DefaultCodec.class);
      codec = ReflectionUtils.newInstance(codecClass, job);
    }

    // ignore the progress parameter, since MapFile is local
    final MapFile.Writer out = new MapFile.Writer(job, fs, file.toString(),
        job.getOutputKeyClass().asSubclass(WritableComparable.class), job
            .getOutputValueClass().asSubclass(Writable.class),
        compressionType, codec, progress);

    return new RecordWriter<WritableComparable, Writable>() {

      private int nbRecord = 0;

      public void write(WritableComparable key, Writable value)
          throws IOException {
        nbRecord++;
        out.append(key, value);
      }

      public void close(Reporter reporter) throws IOException {
        out.close();
        if (nbRecord == 0) { // if there are no records outputed
          // TODO: Changed to use LazyOutputFormat, which is not
          // available in hadoop 0.20.2
          return;
        }
        // zip the mapfile
        // the file cannot be at the root, otherwise the parent is
        // null...
        final Path zipPath = new Path(file.getParent(), MAPFILE_ZIP_NAME);
        // if zipPath already exists, it will overwritten!
        final ZipOutputStream zipout = new ZipOutputStream(
            new BufferedOutputStream(fs.create(zipPath)));
        try {
          for (String name : mfFiles) {
            final Path newFile = new Path(file, name);
            final ZipEntry entry = new ZipEntry(name);
            entry.setSize(fs.getFileStatus(newFile).getLen());
            zipout.putNextEntry(entry);

            final BufferedInputStream r = new BufferedInputStream(
                fs.open(newFile));
            final byte[] bytes = new byte[32];
            int read = 0;

            try {
              while ((read = r.read(bytes)) != -1) {
                zipout.write(bytes, 0, read);
              }
            } finally {
              zipout.closeEntry();
              r.close();
            }
          }
        } finally {
          zipout.close();
        }
      }
    };
  }

  /** Open the output generated by this format. */
  public static MapFile.Reader[] getReaders(FileSystem ignored, Path dir,
      Configuration conf) throws IOException {
    FileSystem fs = dir.getFileSystem(conf);
    Path[] names = FileUtil.stat2Paths(fs.listStatus(dir));

    // sort names, so that hash partitioning works
    Arrays.sort(names);

    MapFile.Reader[] parts = new MapFile.Reader[names.length];
    for (int i = 0; i < names.length; i++) {
      parts[i] = new MapFile.Reader(fs, names[i].toString(), conf);
    }
    return parts;
  }

  /** Get an entry from output generated by this class. */
  public static <K extends WritableComparable<?>, V extends Writable> Writable getEntry(
      MapFile.Reader[] readers, Partitioner<K, V> partitioner, K key, V value)
      throws IOException {
    int part = partitioner.getPartition(key, value, readers.length);
    return readers[part].get(key, value);
  }

}
